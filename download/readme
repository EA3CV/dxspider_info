# DXSpider – Automatic Bad Lists Update

This repository provides scripts and data files to safely maintain and update
DXSpider “bad lists”:

- bad words
- bad nodes
- bad DX calls
- bad spotters

The update mechanism is intentionally split into two phases:

1. **Download** updated .new files (typically via cron)
2. **Merge and load** those files into DXSpider using load/* scripts

This approach guarantees no data loss, no overwrites, and no duplicates.

---

## Prerequisites

- A working DXSpider installation
- Internet access from the DXSpider host

---

## Required load scripts (mandatory)

Before enabling **any automatic download**, you **must install** the following
four scripts:

- badwords.pl
- badnode.pl
- baddx.pl
- badspotter.pl

These scripts are responsible for merging newly downloaded data with the
existing DXSpider data structures.

---

## Installation directory

All scripts must be installed in:

/spider/local_cmd/load


If the directory does not exist, create it:

mkdir -p /spider/local_cmd/load

---

## Download the load scripts

Download the **raw files** from GitHub:

wget -O /spider/local_cmd/load/badwords.pl https://raw.githubusercontent.com/EA3CV/dxspider_info/main/load/badwords.pl
wget -O /spider/local_cmd/load/badnode.pl https://raw.githubusercontent.com/EA3CV/dxspider_info/main/load/badnode.pl
wget -O /spider/local_cmd/load/baddx.pl https://raw.githubusercontent.com/EA3CV/dxspider_info/main/load/baddx.pl
wget -O /spider/local_cmd/load/badspotter.pl https://raw.githubusercontent.com/EA3CV/dxspider_info/main/load/badspotter.pl

---

## Set execution permissions

chmod +x /spider/local_cmd/load/*.pl

---

## What the load scripts do

Each load/* script performs the following steps:

1. Reads the list currently loaded in DXSpider memory
2. Reads the corresponding .new file downloaded from disk
3. Merges both sources without duplicates
4. Preserves all locally defined entries
5. Writes the updated result back to disk in the correct DXSpider format

The scripts are **idempotent** and safe to run multiple times.

---

## Manual usage (recommended test)

Before enabling cron, test the scripts manually from inside DXSpider:

load/badwords
load/badnode
load/baddx
load/badspotter

No parameters are required.

---

## Automatic downloads using cron

Once **all four load scripts are installed and tested**, you may enable
automatic downloads using cron

Cron jobs **only download** the .new files.
They do **not** load or merge any data by themselves.

### Example crontab
                                                    
# badip
30 * * * * spawn('cd /spider/local_data; wget -qN https://raw.githubusercontent.com/EA3CV/dxspider_info/main/download/badip.torexit')
30 * * * * spawn('cd /spider/local_data; wget -qN https://raw.githubusercontent.com/EA3CV/dxspider_info/main/download/badip.torrelay')
30 * * * * spawn('cd /spider/local_data; wget -qN https://raw.githubusercontent.com/EA3CV/dxspider_info/main/download/badip.global')
32 * * * * run_cmd('load/badip')

# baddx, badspotter, badnode, badword
33 * * * * spawn('cd /spider/local_data; wget -qN https://raw.githubusercontent.com/EA3CV/dxspider_info/main/download/baddx.new')
34 * * * * run_cmd('load/baddx')
35 * * * * spawn('cd /spider/local_data; wget -qN https://raw.githubusercontent.com/EA3CV/dxspider_info/main/download/badspotter.new')
36 * * * * run_cmd('load/badspotter')
37 * * * * spawn('cd /spider/local_data; wget -qN https://raw.githubusercontent.com/EA3CV/dxspider_info/main/download/badnode.new')
37 * * * * run_cmd('load/badnode')
39 * * * * spawn('cd /spider/local_data; wget -qN https://raw.githubusercontent.com/EA3CV/dxspider_info/main/download/badword.new')
40 * * * * run_cmd('load/badwords')

---

## Author

Kin, EA3CV
